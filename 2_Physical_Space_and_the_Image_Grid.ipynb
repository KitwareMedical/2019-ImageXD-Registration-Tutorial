{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Physical Space and the Image Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learning Objectives\n",
    "\n",
    "* Understand how an **image pixel grid** is defined in **physical space**\n",
    "* Understand how a **spatial transform** *defines the map between two physical spaces*\n",
    "* Understand **how to define a resampling operation** to generate a new image grid\n",
    "* Understand the **role of image interpolators**, and become familiar with a few common interpolators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Physical Space, Images, and the Pixel Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When performing image registration, where the object is to find the spatial transform that maps between the fixed image space and the moving image space, it is **extremely important** to have clear definitions of **physical space**, aka **world space**, and how images live in these spaces.\n",
    "\n",
    "Once we have *good definitions* and *follow them consistently*, operations such resampling, interpolation, multi-resolution processing, and spatial transform as are **clear** and **correct**, even on images that **anisotropic**, **oriented**, or with **multi-component tensor pixels**, such as gradient vectors or diffusion tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Problem: Register a Human Lung Volume from Two Time Points\n",
    "\n",
    "Given a problem to register x-ray computed tomography (CT) images of a human lung taken at two time points, **what must be supported?**\n",
    "\n",
    "In image registration, we typically identify the two images as the **fixed** and **moving** image. Our goal is to **find the spatial transformation that makes the moving image so align with the fixed image**. Our fixed image was acquired from the patient at a baseline time point, and our moving image was acquired at a follow-up time point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, let's examine our fixed and moving images.\n",
    "\n",
    "We will use the [`itkwidgets`](https://github.com/InsightSoftwareConsortium/itkwidgets), interative Jupyter widgets to visualize images, point sets, and meshes in 2D and 3D.\n",
    "\n",
    "The `itkwidgets` are built on [The Insight Toolkit (ITK)](https://github.com/InsightSoftwareConsortium/ITK). ITK is an open-source, cross-platform toolkit for N-dimensional scientific image processing, segmentation, and registration. ITK has been collaboratively developed by a large community of research software engineers for over 20 years and serves as the foundation for many popular image registration tools such as [ANTs](https://github.com/ANTsX/ANTsPy), [elastix](http://elastix.isi.uu.nl/), or [ndreg](https://github.com/InsightSoftwareConsortium/ITKNDReg/).\n",
    "\n",
    "ITK is one of the few libraries that supports a wide variety of parametric spatial transformation models and an HDF5 file format to serialize and deserialize these models. Spatial transformation models range from rigid, similarity, affine, kernel-based spline, b-spline, to dense displacement fields and composite transformations. The HDF5 file format, important for reproducibility, transform quantification, and avoiding resampling issues related to data size, precision, and interpolation, has been adopted by projects such as [3D Slicer](https://slicer.org/) for medical imaging, [DREAM.3D](dream3d.bluequartz.net/) for material science imaging, and the [Brain Imaging Data Structure (BIDS)](https://bids.neuroimaging.io/) for neuroimaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import itk\n",
    "from itkwidgets import view, checkerboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad2ca04382d457fbf16d6652487a182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[], gradient_opacity=0.22, mode='x', point_sets=[], rendered_image=<itkImagePython.itkImageS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fixed_image = itk.imread('imgs/CT_3D_lung_fixed.mha')\n",
    "\n",
    "view(fixed_image, mode='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The CT image provides radiodensity in [Hounsefield units](https://en.wikipedia.org/wiki/Hounsfield_scale); lung tissue approaches -1000 in intensity, the value for air, and soft tissue is slightly above 0 intensity, the value for water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a5aedb20a045eeb3858f9d4e6c976b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(annotations=False, geometries=[], gradient_opacity=0.5, point_sets=[], rendered_image=<itkImagePython.i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view(fixed_image, vmax=-300, gradient_opacity=0.5, ui_collapsed=True, annotations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82cc94b8ff3471fab0ec03114134d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(annotations=False, geometries=[], gradient_opacity=0.22, point_sets=[], rendered_image=<itkImagePython.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view(fixed_image, vmin=-50, vmax=500, ui_collapsed=True, annotations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itkVectorD3 ([1.366, 1.366, 2.5])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b258e45b7947fb81ffcc5c91120646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[], gradient_opacity=0.22, mode='z', point_sets=[], rendered_image=<itkImagePython.itkImageS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(fixed_image.GetSpacing())\n",
    "\n",
    "view(fixed_image, mode='z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Take-home observations**:\n",
    "\n",
    "- The resolution is anisotropic; resolution is higher in-plane versus out-of-plane.\n",
    "- The pixel type is signed short: registration requires supporting this pixel type and interpolating samples between these pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can compare the fixed and moving images by interleaving them in a checkboard pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02172e85f5374c9d8ed73fcbf8e9c20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Viewer(annotations=False, gradient_opacity=0.5, interpolation=False, rendered_image=<itkImagePy…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "moving_image = itk.imread('imgs/CT_3D_lung_moving.mha')\n",
    "\n",
    "checkerboard(moving_image, fixed_image,\n",
    "             mode='v', ui_collapsed=False, slicing_planes=True, gradient_opacity=0.5, shading=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Discussion question**: how is a checkerboard created if the images are not sampled on the same image grid?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We **conceptualize** a **spatial image** as a **uniform grid of pixels** or **pixel grid** that lives is physical space.\n",
    "\n",
    "Let's continue [with this presentation](https://docs.google.com/presentation/d/1TGjGseDGa_IjrBWA5aMLzxKssy0Al5KT-_FmGlYF92Y/edit?usp=sharing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise: Lung image size\n",
    "\n",
    "There are two 3D CT lung images, sampled on different image grids:\n",
    "\n",
    "1. *imgs/CT_3D_lung_fixed.mha*\n",
    "2. *imgs/CT_3D_lung_fixed_small.mha*\n",
    "\n",
    "Which is larger in terms of its:\n",
    "\n",
    "* File size?\n",
    "* Spatial domain?\n",
    "* Resolution?\n",
    "\n",
    "How much less time will it take to register *CT_3D_lung_fixed_small.mha* to *CT_3D_lung_moving.mha*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CT_3D_lung_fixed.mha\t    CT_3D_lung_moving.mha  phantom.tif\r\n",
      "CT_3D_lung_fixed_small.mha  phantom2.tif\r\n"
     ]
    }
   ],
   "source": [
    "!ls imgs"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
