{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Image Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Learning Objectives\n",
    "\n",
    "* Define the **registration problem**: *find the spatial transformation that aligns images in the presence of noise*\n",
    "* Understand how insights can be obtained from both *resampled images* and the *spatial transformation*\n",
    "* Understand how registration helps\n",
    "\n",
    "  * Compare multiple modalities\n",
    "  * Align multiple modalities for convolutional neural net segmentation\n",
    "  * Track changes over time\n",
    "  * Place structures in a common coordinate system, e.g. an image atlas\n",
    "  * Segment images by registering to an atlas\n",
    "  * Quantify how structures shrink and grow\n",
    "\n",
    "* Learn how to perform a general 3D image registration in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "Todo: add a link to the slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise: 3D Image Registration of the Lung "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Problem: Register a Human Lung Volume from Two Time Points\n",
    "\n",
    "In this exercise, we register x-ray computed tomography (CT) images of a human lung taken at two time points.\n",
    "\n",
    "In image registration, we typically identify the two images as the **fixed** and **moving** image. Our goal is to **find the spatial transformation that makes the moving image so align with the fixed image**. Our fixed image was acquired from the patient at a baseline time point, and our moving image was acquired at a follow-up time point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, let's examine our fixed and moving images.\n",
    "\n",
    "We will use the [`itkwidgets`](https://github.com/InsightSoftwareConsortium/itkwidgets), interative Jupyter widgets to visualize images, point sets, and meshes in 2D and 3D.\n",
    "\n",
    "The `itkwidgets` are built on [The Insight Toolkit (ITK)](https://github.com/InsightSoftwareConsortium/ITK). ITK is an open-source, cross-platform toolkit for N-dimensional scientific image processing, segmentation, and registration. ITK has been collaboratively developed by a large community of research software engineers for over 20 years and serves as the foundation for many popular image registration tools such as [ANTs](https://github.com/ANTsX/ANTsPy), [elastix](http://elastix.isi.uu.nl/), or [ndreg](https://github.com/InsightSoftwareConsortium/ITKNDReg/).\n",
    "\n",
    "ITK is one of the few libraries that supports a wide variety of parametric spatial transformation models and an HDF5 file format to serialize and deserialize these models. Spatial transformation models range from rigid, similarity, affine, kernel-based spline, b-spline, to dense displacement fields and composite transformations. The HDF5 file format, important for reproducibility, transform quantification, and avoiding resampling issues related to data size, precision, and interpolation, has been adopted by projects such as [3D Slicer](https://slicer.org/) for medical imaging, [DREAM.3D](dream3d.bluequartz.net/) for material science imaging, and the [Brain Imaging Data Structure (BIDS)](https://bids.neuroimaging.io/) for neuroimaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import itk\n",
    "from itkwidgets import view, checkerboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa52192cf6a4014aaa7a377438e7457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[], gradient_opacity=0.22, mode='x', point_sets=[], rendered_image=<itkImagePython.itkImageS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fixed_image = itk.imread('imgs/CT_3D_lung_fixed.mha')\n",
    "\n",
    "view(fixed_image, mode='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The CT image provides radiodensity in [Hounsefield units](https://en.wikipedia.org/wiki/Hounsfield_scale); lung tissue approaches -1000 in intensity, the value for air, and soft tissue is slightly above 0 intensity, the value for water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e12f716d48b4ffc971a1e651c89000c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(annotations=False, geometries=[], gradient_opacity=0.5, point_sets=[], rendered_image=<itkImagePython.i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view(fixed_image, vmax=-300, gradient_opacity=0.5, ui_collapsed=True, annotations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6485bda773454ab8a8e5794c70e4b87d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(annotations=False, geometries=[], gradient_opacity=0.22, point_sets=[], rendered_image=<itkImagePython.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view(fixed_image, vmin=-50, vmax=500, ui_collapsed=True, annotations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itkVectorD3 ([1.366, 1.366, 2.5])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b89439b6a34ecbbbbec805d83e8c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[], gradient_opacity=0.22, mode='z', point_sets=[], rendered_image=<itkImagePython.itkImageS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(fixed_image.GetSpacing())\n",
    "\n",
    "view(fixed_image, mode='z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The resolution is anisotropic; resolution is higher in-plane versus out-of-plane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can compare the fixed and moving images by interleaving them in a checkboard pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec144e69d3e4ba38fe58172f46030bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Viewer(annotations=False, gradient_opacity=0.5, interpolation=False, rendered_image=<itkImagePy…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "moving_image = itk.imread('imgs/CT_3D_lung_moving.mha')\n",
    "\n",
    "checkerboard(moving_image, fixed_image,\n",
    "             mode='v', ui_collapsed=False, slicing_planes=True, gradient_opacity=0.5, shading=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `itkwidgets` are built on [The Insight Toolkit (ITK)](https://github.com/InsightSoftwareConsortium/ITK). ITK is an open-source, cross-platform toolkit for N-dimensional scientific image processing, segmentation, and registration. ITK has been collaboratively developed by a large community of research software engineers for over 20 years and serves as the foundation for many popular image registration tools such as [ANTs](https://github.com/ANTsX/ANTsPy), [elastix](http://elastix.isi.uu.nl/), or [ndreg](https://github.com/InsightSoftwareConsortium/ITKNDReg/). ITK contains registration tools for landmark-based registration, optical-flow-based registration, and parameteric optimization-based registration.\n",
    "\n",
    "ITK is one of the few libraries that supports a wide variety of parametric spatial transformation models and an HDF5 file format to serialize and deserialize these models. Spatial transformation models range from rigid, similarity, affine, kernel-based spline, b-spline, to dense displacement fields and composite transformations. The HDF5 file format, important for reproducibility, transform quantification, and avoiding resampling issues related to data size, precision, and interpolation, has been adopted by projects such as [3D Slicer](https://slicer.org/) for medical imaging, [DREAM.3D](dream3d.bluequartz.net/) for material science imaging, and the [Brain Imaging Data Structure (BIDS)](https://bids.neuroimaging.io/) for neuroimaging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Discussion question**: how can we use the registration to gain insights into the lung images?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
